{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to import required dependencies:\nnumpy: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.9 from \"C:\\Users\\M\\anaconda3\\envs\\nfts_nba_extraction_env\\python.exe\"\n  * The NumPy version is: \"1.21.2\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: DLL load failed while importing _multiarray_umath: The specified module could not be found.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3408/1793542903.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Import pandas as pd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nfts_nba_extraction_env\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmissing_dependencies\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     raise ImportError(\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[1;34m\"Unable to import required dependencies:\\n\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_dependencies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     )\n",
      "\u001b[1;31mImportError\u001b[0m: Unable to import required dependencies:\nnumpy: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.9 from \"C:\\Users\\M\\anaconda3\\envs\\nfts_nba_extraction_env\\python.exe\"\n  * The NumPy version is: \"1.21.2\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: DLL load failed while importing _multiarray_umath: The specified module could not be found.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import os\n",
    "# Import pandas as pd\n",
    "import pandas as pd\n",
    "import glob\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete old moments data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'G:\\\\My Drive\\\\Data Science\\\\Data Science Projects\\\\NFTs\\\\GitHub\\\\nfts_nba_extraction'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = time.time()\n",
    "\n",
    "moments_folder = os.getcwd() + \"\\\\moments_data\"\n",
    "\n",
    "files = [os.path.join(moments_folder, filename) for filename in os.listdir(moments_folder)]\n",
    "for filename in files:\n",
    "    if (now - os.stat(filename).st_mtime) > 60:\n",
    "        try:\n",
    "            os.remove(filename)\n",
    "        except OSError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download new moments' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download new moments' data\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "\n",
    "#os.getcwd()\n",
    "\n",
    "prefs = {'download.default_directory' : moments_folder}\n",
    "chrome_options.add_experimental_option('prefs', prefs)\n",
    "driver = webdriver.Chrome(executable_path='chromedriver', options=chrome_options)\n",
    "\n",
    "#driver = webdriver.Chrome(executable_path='chromedriver')\n",
    "time.sleep(3)\n",
    "\n",
    "driver.get('https://otmnft.com/moments/')#put here the adress of your page\n",
    "moments_btn = driver.find_element(By.XPATH, '/html/body/div[3]/div[2]/div/form/div[1]/div/div/div[3]/center/button[2]')\n",
    "moments_btn.click()\n",
    "time.sleep(4)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the latest moments data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path for the latest moments data\n",
    "latest_moments_path= moments_folder + '\\\\moments*.csv'\n",
    "\n",
    "# Create dict specifying data types for Series and zipcode\n",
    "data_types = {\"Series\": \"category\", \"zipcode\": str}\n",
    "\n",
    "date_columns = ['Time Stamp (EST)', 'Date of Moment']\n",
    "\n",
    "try:\n",
    "    \n",
    "    # Read the latest moments file\n",
    "    list_of_files = glob.glob(latest_moments_path) # * means all if need specific format then *.csv\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    \n",
    "    # Read the CSV and assign it to the variable moments\n",
    "    moments = pd.read_csv(latest_file, dtype= data_types, parse_dates=date_columns)\n",
    "        \n",
    "    moments = moments[~moments.Set.str.contains(\"WNBA|In Her Bag\")]\n",
    "\n",
    "    moments = moments.rename(columns={'Date of Moment': 'date_of_moment', 'Player Name': 'player_name'})\n",
    "\n",
    "    moments['date_of_moment'] = pd.to_datetime(moments.date_of_moment).dt.tz_localize(None)\n",
    "    \n",
    "except pd.io.common.CParserError:\n",
    "    print(\"Your data contained rows that could not be parsed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moments['player_name'] = moments['player_name'].str.replace('.', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moments['Time Stamp (EST)'] = moments['Time Stamp (EST)'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "five_thirty_eight_path = os.getcwd() + \"\\\\five_thirty_eight\\\\pcapmv.xlsx\"\n",
    "\n",
    "# Read spreadsheet and assign it to survey_responses\n",
    "five_thirty_eight = pd.read_excel(five_thirty_eight_path, engine='openpyxl')\n",
    "\n",
    "five_thirty_eight['player'] = five_thirty_eight['player'].str.title()\n",
    "\n",
    "name_suffixes_replacement = {\"Iii\": \"III\", \"Ii\": \"II\"}\n",
    "\n",
    "five_thirty_eight['player'] = five_thirty_eight['player'].replace(name_suffixes_replacement, regex=True)\n",
    "\n",
    "five_thirty_eight['age'] = five_thirty_eight['age'].str.replace(' years old', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_value_replacement = {\"\\$\": \"\", \"m\": \"\"}\n",
    "\n",
    "five_thirty_eight['market_value'] = five_thirty_eight['market_value'].replace(market_value_replacement, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "\n",
    "difflib.get_close_matches\n",
    "\n",
    "five_thirty_eight.player = five_thirty_eight.player.map(lambda x: difflib.get_close_matches(x, moments.player_name, cutoff=0.8))\n",
    "\n",
    "five_thirty_eight[\"player\"] = five_thirty_eight[\"player\"].str[0]\n",
    "\n",
    "five_thirty_eight['player'] = five_thirty_eight['player'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge five_thirty_eight into moments on the player_name\n",
    "merged_df = five_thirty_eight.merge(moments, how='right', left_on=\"player\",right_on=\"player_name\")\n",
    "\n",
    "merged_df = merged_df.drop('player', axis=1)\n",
    "\n",
    "merged_df['moments_count'] = merged_df.groupby(['player_name'])['category'].transform('count')\n",
    "\n",
    "merged_df_new= pd.crosstab(merged_df.player_name,merged_df.Series)\n",
    "\n",
    "merged_df_new = merged_df_new.stack().reset_index().rename(columns={0:'series_count'})\n",
    "\n",
    "merged_df_new['Series'] = merged_df_new['Series'].map({'1':'CS1', '2':'CS2', '3':'CS3', '4':'CS4'}) \n",
    "\n",
    "merged_df_new = merged_df_new.pivot_table(values='series_count', index=['player_name'], columns=['Series'], aggfunc='sum')\n",
    "\n",
    "merged_df_new.fillna(0, inplace= True)\n",
    "\n",
    "merged_df_new['player_name'] = merged_df_new.index\n",
    "\n",
    "merged_df_new.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge five_thirty_eight into moments on the player_name\n",
    "moments_538 = merged_df.merge(merged_df_new,on=\"player_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moments_538['Low Ask'] = moments_538['Low Ask'].astype(int)\n",
    "\n",
    "moments_538['cs_per_dollar'] = moments_538['Collector Score']/moments_538['Low Ask']\n",
    "\n",
    "moments_538['cs_per_dollar'] = moments_538['cs_per_dollar'].round(2)\n",
    "\n",
    "moments_538['market_cap']= moments_538['Circulation Count']*moments_538['Low Ask']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete old NBA Stats data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_folder = os.getcwd() + \"\\\\stats_data\"\n",
    "\n",
    "files = [os.path.join(stats_folder, filename) for filename in os.listdir(stats_folder)]\n",
    "for filename in files:\n",
    "    if (now - os.stat(filename).st_mtime) > 60:\n",
    "        try:\n",
    "            os.remove(filename)\n",
    "        except OSError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download NBA Stats data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.getcwd()\n",
    "\n",
    "prefs = {'download.default_directory' : stats_folder}\n",
    "chrome_options.add_experimental_option('prefs', prefs)\n",
    "driver = webdriver.Chrome(executable_path='chromedriver', options=chrome_options)\n",
    "\n",
    "#driver = webdriver.Chrome(executable_path='chromedriver')\n",
    "time.sleep(3)\n",
    "\n",
    "driver.get('https://www.nbastuffer.com/2021-2022-nba-player-stats/') #put here the adress of your page\n",
    "stats_btn = driver.find_element(By.XPATH, '/html/body/div[1]/div/div[1]/div/div/article/div/div/div[3]/div/div[1]/button/span')\n",
    "stats_btn.click()\n",
    "time.sleep(4)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the latest NBA Stats data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path for the latest stats data\n",
    "latest_stats_path= stats_folder + '\\\\NBA*.xlsx'\n",
    "\n",
    "# Create dict specifying data types for Series and zipcode\n",
    "#data_types = {\"Series\": \"category\", \"zipcode\": str}\n",
    "\n",
    "try:\n",
    "    \n",
    "    # Read the latest stats file\n",
    "    list_of_stats_files = glob.glob(latest_stats_path) # * means all if need specific format then *.csv\n",
    "    latest_stats_file = max(list_of_stats_files, key=os.path.getctime)\n",
    "    \n",
    "    cols2skip = [0,2,3,4]  \n",
    "    cols = [i for i in range(29) if i not in cols2skip]\n",
    "    \n",
    "    # Read the CSV and assign it to the variable stats\n",
    "    stats = pd.read_excel(latest_stats_file, skiprows=[0], usecols=cols, engine='openpyxl')\n",
    "        \n",
    "    #stats = stats[~stats.Set.str.contains(\"WNBA|In Her Bag\")]\n",
    "\n",
    "    stats = stats.rename(columns={'FULL NAME': 'full_name', 'MIN%Minutes PercentagePercentage of team minutes used by a player while he was on the floor': 'minutes_percentage', 'USG%Usage RateUsage rate, a.k.a., usage percentage is an estimate of the percentage of team plays used by a player while he was on the floor': 'usage_rate', 'TO%Turnover RateA metric that estimates the number of turnovers a player commits per 100 possessions': 'turnover_rate', 'eFG%Effective Shooting PercentageWith eFG%, three-point shots made are worth 50% more than two-point shots made. eFG% Formula=(FGM+ (0.5 x 3PM))/FGA': 'effective_shooting_percentage', 'TS%True Shooting PercentageTrue shooting percentage is a measure of shooting efficiency that takes into account field goals, 3-point field goals, and free throws.': 'true_shooting_percentage', 'PPGPointsPoints per game.': 'points_per_game', 'RPGReboundsRebounds per game.': 'rebounds_per_game', 'TRB%Total Rebound PercentageTotal rebound percentage is estimated percentage of available rebounds grabbed by the player while the player is on the court.': 'total_rebound_percentage', 'APGAssistsAssists per game.': 'assists_per_game', 'AST%Assist PercentageAssist percentage is an estimated percentage of teammate field goals a player assisted while the player is on the court': 'assist_percentage', 'SPGStealsSteals per game.': 'steals_per_game', 'BPGBlocksBlocks per game.': 'blocks_per_game', 'TOPGTurnoversTurnovers per game.': 'turnovers_per_game', 'VIVersatility IndexVersatility index is a metric that measures a player’s ability to produce in points, assists, and rebounds. The average player will score around a five on the index, while top players score above 10': 'versatility_index', 'ORTGOffensive RatingIndividual offensive rating is the number of points produced by a player per 100 total individual possessions.': 'offensive_rating', 'DRTGDefensive RatingIndividual defensive rating estimates how many points the player allowed per 100 possessions he individually faced while staying on the court.': 'defensive_rating'})\n",
    "    \n",
    "except pd.io.common.CParserError:\n",
    "    print(\"Your data contained rows that could not be parsed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the latest NBA Stats data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.full_name = stats.full_name.map(lambda x: difflib.get_close_matches(x, moments_538.player_name, cutoff=0.8))\n",
    "\n",
    "stats[\"full_name\"] = stats[\"full_name\"].str[0]\n",
    "\n",
    "stats['full_name'] = stats['full_name'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge five_thirty_eight into moments on the player_name\n",
    "moments_538_stats = moments_538.merge(stats, how='right', left_on=\"player_name\",right_on=\"full_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moments_538_stats = moments_538_stats[moments_538_stats['player_name'].notna()]\n",
    "moments_538_stats = moments_538_stats.drop('full_name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulated_data_path = os.getcwd() + '\\\\accumulated_data\\\\merged_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_data = pd.read_csv(accumulated_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refreshed_df= pd.concat([existing_data, moments_538_stats], axis=0, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9982519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "refreshed_df = refreshed_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refreshed_df.to_csv(accumulated_data_path, sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "print('\\n Success! Your moments data has been updated in', int(end - start), 'seconds.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfts_nba_extraction_kernel",
   "language": "python",
   "name": "nfts_nba_extraction_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
